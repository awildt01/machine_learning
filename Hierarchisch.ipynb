{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Cluster Analysis - Hierarchische Methoden**\n",
    "\n",
    "Um hierarchischen Clustering geht es um eine unbeaufsichtigte maschinelle Lernmethode, mit der Sie Untergruppen, basierend auf dem Unterschied zwischen Datenpunkten und ihren nächsten Nachbarn vorhersagen können.\n",
    "\n",
    "Diese haben eine gewisse Entfernung voneinander und jeder Datenpunkt ist mit seinem Nachbarn verknüpft, zumindest mit dem Nachbarn, der sich entsprechend der von Ihnen ausgewählten Distanzmetrik in der Nähe befindet. Man muss also bei diesem Konzept erstmal die Entfernung finden, die Entfernung zu den Nachbarn ermitteln und dann muss man Verbindungen schaffen mit den nächsten Nachbarn.\n",
    "\n",
    "1. **Finden** Entfernung\n",
    "\n",
    "2. **Verbinden** mit den näschten Nachbar\n",
    "\n",
    "Durch so ein hierarchisches Clustering werden Untergruppen innerhalb von Daten vorhergesagt, indem man Abstand zwischen jedem Datenpunkt und seinem nächsten Nachbarn ermittelt und dann die nächsten gelegenen Nachbar miteinander eben verbunden werden.Die Anzahl der Untergruppen, die für ein hierarchisches Clustering-Modell geeignet sind, können Sie anhand eines Dendrogramms ermitteln. Ein Dendrogramm ist ein Baumdiagramm, so wie Sie es hier sehen, das zur visuellen Anzeige von verschiedenen Dingen genutzt werden kann, etwa Verwandschaftsbeziehung, Abstammungslinien, oder auch allgemein Taxonomien. Unter so einer Taxonomie versteht man ein einheitliches Verfahren oder Modell, mit dem Objekte nach bestimmten Kriterien klassifiziert werden, man bildet also Klassifizierungsschemen.\n",
    "\n",
    "Es gibt nun eine ganze Reihe an möglichen Anwendungsfällen für so ein hierarchisches Clustering. Man kann an das Ressourcen-Management in einem Krankenhaus denken, Geschäftsprozess-Management, man kann Kundensegmentierung sich vorstellen, oder auch die Analyse sozialer Netzwerke. Für das hierarchische Clustering-Modell müssen Sie dem Modell mitteilen, wie viele Zentren verwendet werden sollen. \n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                 \n",
    "|Entfernung metriken|Verbindungsparameter| \n",
    "|-------------------|--------------------|\n",
    "| Euklidische distanz  |  ward(station)|                        \n",
    "| manhattan distanz  |  complete(komplete)|\n",
    "|kosinus distanz |  Average(durchschnitt)|\n",
    "\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ein Beispiel: Sie wollen die funktionellen Gruppen von Genen identifizieren, indem Sie alle in einer Zelle aktiven Gene identifizieren und dann versuchen diese zu kopieren. Und wenn Sie sich dann für eine hierarchische Gruppierung entscheiden, dann versuchen Sie Gruppen anhand des Abstands zwischen den Datenpunkten und ihren nächsten Nachbarn in einem Gen Expression Profile zu identifizieren. Datenpunkte, die am ähnlichsten sind, werden in derselben genetischen Funktionsgruppe zusammengefasst. \n",
    "\n",
    "\n",
    "In diese Aufgabe werden wir eine cvs Dataset benutzen.Die Datei beinhalte  Sportautos Eigenschaften. Wir werden uns Insbesondere auf die Spalte **am** Konzentrieren. Hier wird nämlich durch einen binären Wert gekennzeichnet, ob ein Auto ein Automatikgetriebe oder ein Schaltgetriebe hat. Und um mal anzudeuten, wo es hingehen könnte, man könnte ja gucken, was haben Autos mit einem Schaltgetriebe an Gemeinsamkeiten, was haben Autos mit einem Automatikgetriebe an Gemeinsamkeiten, und in diese Richtung eine Auswertung beispielsweise vornehmen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import sklearn.metrics as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Spaltenbeschriftungen werden genau entsprechend des Aufbaus der Datei gewählt. \n",
    "\n",
    "Wir werden eine Teilmenge X betrachten und wir werden nur die Variablen **mpg, disp, hp und wt** betrachten. \n",
    "\n",
    "Das sind Angaben zum Kraftstoffverbrauch, dem Hubraum, der Leistung und dem Gewicht. Und wir identifizieren diese anhand der Indizes der Spalten mittels dieses Indexers. Also, der Index 1 steht für mpg, 3 disp, 4 hp und 6 für wt, weight.\n",
    "\n",
    "Da wir die Werte aus den Spalten haben wollen, steht hier natürlich wieder values, also .values Und damit extrahieren wir eine Teilmenge der Gesamtdaten. Unsere Ziel-Variable wird am sein und das ist ja die Aussage, ob es sich um ein Schaltgetriebe oder ein Automatikgetriebe handelt und die steht beim Index 9. \n",
    "\n",
    "\n",
    "Die Ziel-Variable Y wird auch mit einem Indexer ermittelt und die Werte werden mit Values zurückgegeben. Unsere Ziel-Variable wird am sein und das ist ja die Aussage, ob es sich um ein Schaltgetriebe oder ein Automatikgetriebe handelt und die steht beim Index 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'mtcars\\mtcars.csv'\n",
    "cars = pd.read_csv(address)\n",
    "cars.columns = ['car_names','mpg','cyl','disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
    "\n",
    "X = cars.iloc[:,[1,3,4,6]].values\n",
    "\n",
    "y = cars.iloc[:,[9]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Verwendung von scipy zum Erstellen des Dendrogramms**\n",
    "\n",
    "\n",
    "\n",
    "Wir haben zuerst eine Verknüpfungsfunktion **(Linkage)** X sind die Daten, die hier verknüpft werden.\n",
    "\n",
    "Diese Funktion führt das hierarchische Clustering auf Basis unserer Daten durch und mit dem entsprechenden zweiten Argument wird die Art der Verknüpfung festgelegt, in diesem Fall das Wort-Argument **ward**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(X, 'ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendrogram erzeugen:\n",
    "\n",
    "Dieser Funktion, Dendrogramm, wird Z übergeben, was die Rückgabe von dieser linkage-Funktion repräsentiert.\n",
    "\n",
    "Dieser Funktion, Dendrogramm, wird Z übergeben, was die Rückgabe von dieser linkage-Funktion repräsentiert. Z sind die Clustering-Ergebnisse, die von dem Algorithmus von dem Framework generiert wurden.\n",
    "\n",
    "Mit beiden Zeilenl plt.axhline(y=500) plt.axhline(y=150) werden Linien in das Diagramm gezogen, anhand derer man an den Schnittpunkten erkennen kann, wie viele Cluster man bauen soll, einmal bei der Entfernung 150 und einmal bei der Entfernung 500. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram(Z, truncate_mode='lastp', p=12, leaf_rotation=45., leaf_font_size=15., show_contracted=True)\n",
    "\n",
    "plt.title('Verkürztes hierarchisches Clustering-Dendrogramm')\n",
    "plt.xlabel('Clustergröße')\n",
    "plt.ylabel('Entfernung')\n",
    "\n",
    "plt.axhline(y=500)\n",
    "plt.axhline(y=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchische Cluster generieren\n",
    "k ist zwei cluster.\n",
    "\n",
    "Genauigkeit-Score-Funktion von sklearn verwenden, um unser Modell zu bewerten, das macht hier diese Methode accuracy_score. Parameter sind unsere Zielvariable Y und die vorhergesagten Werte, die aus unserem hierarchischen Clustering-Modell generiert wurden. Wenn wir das ausführen, werden wir herausfinden, wie gut dieses Modell arbeitet. Wir bekommen den Wert 0,78, also, 78% etwa.\n",
    "\n",
    "Der Wert 1 steht für 100% und das ist die optimale Ausbeute, die wir erreichen können und 0 die denkbar schlechteste, Werte so um die **80 herum sind ganz brauchbar**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=2\n",
    "\n",
    "Hclustering = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage='ward')\n",
    "Hclustering.fit(X)\n",
    "\n",
    "sm.accuracy_score(y, Hclustering.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird ausprobiert ob durch eine andere Kombination der Parameter nicht bessere Werte erreichen werden. Also über 80% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hclustering = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage='complete')\n",
    "Hclustering.fit(X)\n",
    "\n",
    "sm.accuracy_score(y, Hclustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hclustering = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage='average')\n",
    "Hclustering.fit(X)\n",
    "\n",
    "sm.accuracy_score(y, Hclustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hclustering = AgglomerativeClustering(n_clusters=k, affinity='manhattan', linkage='average')\n",
    "Hclustering.fit(X)\n",
    "\n",
    "sm.accuracy_score(y, Hclustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
